{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Pipelines using MIRI image data from MAST"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Table of Contents:\n",
    "> * [Detector1 Pipeline](#detector1_pipeline)\n",
    "> * [Resources and Documentation](#resources)\n",
    "> * [Download Data from MAST](#download_from_mast)\n",
    "> * [Run Pipeline with Default Configuration](#pipeline_with_defaults)\n",
    "> * [About Configuration Files](#pipeline_configs)\n",
    "> * [Run Pipeline with Configuration Files](#pipeline_with_cfgs)\n",
    "> * [Run Pipeline with Parameters Set Programmatically](#pipeline_no_configs)\n",
    "> * [Run Individual Steps with Configuration Files](#steps_with_config_files)\n",
    "> * [Run Level 1, 2, 3, Pipelines in Succession](#pipelines_level_123)\n",
    "\n",
    "***\n",
    "<a id=detector1_pipeline></a>\n",
    "##  Detector1 Pipeline\n",
    "\n",
    "Stage 1 consists of detector-level corrections that are performed on a group-by-group basis, followed by ramp fitting. \n",
    "\n",
    "More information can be found at: https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipeline/calwebb_detector1.html#calwebb-detector1\n",
    "\n",
    "> **Inputs**: The inputs to stage 1 processing will usually be level-1b raw files.\n",
    "\n",
    "> **Outputs**: The output of stage 1 processing is a countrate image per exposure, or per integration for some modes.\n",
    "    \n",
    "### Level 1 pipeline:\n",
    "\n",
    "**Calwebb Detector1**   (jwst.pipeline, calwebb_detector1, Detector1Pipeline)   (calwebb_detector1.cfg)\n",
    "\n",
    "### Level 1 pipeline steps:\n",
    "\n",
    "**Group Scale** (jwst.group_scale, group_scale_step, GroupScaleStep)   (group_scale.cfg)\n",
    "\n",
    "**DQInit** (jwst.dq_init, dq_init_step, DQInitStep)    (dq_init.cfg)\n",
    "\n",
    "**Saturation** (jwst.saturation, saturation_step, SaturationStep)    (saturation.cfg)\n",
    "\n",
    "**IPC**   (jwst.ipc,  ipc_step,  IPCStep)    (ipc.cfg)\n",
    "\n",
    "**Super Bias**   (jwst.superbias,  superbias_step,  SuperBiasStep)    (superbias.cfg)\n",
    "\n",
    "**Refpix** (jwst.refpix,  refpix_step,  RefpixStep)    (refpix.cfg)\n",
    "\n",
    "**RSCD**   (jwst.rscd,  rscd_step,  RSCD_Step)   (rscd.cfd)\n",
    "\n",
    "**First Frame**  (jwst.firstframe, firstframe_step,  FirstFrameStep)   (firstframe.cfg)\n",
    "\n",
    "**Last Frame**  (jwst.lastframe,  lastframe_step, LastFrameStep)   (lastframe.cfg)\n",
    "\n",
    "**Linearity**  (jwst.linearity,  linearity_step, LinearityStep)   (linearity.cfg)\n",
    "\n",
    "**Dark Current**  (jwst.dark_current,  dark_current_step,  DarkCurrentStep)   (dark_current.cfg)\n",
    "\n",
    "**Peristence**  (jwst.persistence,  persistence_step, PersistenceStep)   (persistence.cfg)\n",
    "\n",
    "**Jump**  (jwst.jump, jump_step,  JumpStep)  (jump_step.cfg)\n",
    "\n",
    "**RampFit**   (jwst.ramp_fit,  ramp_fit_step,  RampFitStep)   (ramp_fit_step.cfg)\n",
    "\n",
    "**Gain Scale**  (jwst.gain_scale,  gain_scale_step,  GainScaleStep)   (gain_scale_step.cfg)\n",
    "\n",
    "(for more information on individual steps see: https://jwst-pipeline.readthedocs.io/en/latest/jwst/package_index.html)\n",
    "\n",
    "***\n",
    "<a id='resources'></a>\n",
    "## Resources and Documentation\n",
    "\n",
    "There are several different places to find information on installing and running the pipeline. This notebook will give a shortened description of the steps pulled from the detailed pipeline information pages, but to find more in-depth instructions use the links below. \n",
    "\n",
    ">1. JDox: https://jwst-docs.stsci.edu/display/JDAT/JWST+Data+Reduction+Pipeline\n",
    ">2. Installation page: http://astroconda.readthedocs.io/en/latest/releases.html#pipeline-install\n",
    ">3. Detailed pipeline information: https://jwst-pipeline.readthedocs.io/en/latest/jwst/introduction.html\n",
    ">4. Help Desk (click on Pipeline Support): https://stsci.service-now.com/jwst?id=sc_category\n",
    ">5. GitHub README installation instructions: https://github.com/spacetelescope/jwst/blob/master/README.md\n",
    "\n",
    "\n",
    "If this is your first time trying to run the pipeline from a jupyter notebook, you need to install the jupyter notebook in your pipeline environment:\n",
    ">1. In a new terminal, change the directory to your working directory, terminal command: cd [your working directory]\n",
    ">2. Terminal command: source activate jwst_dev\n",
    "(or whatever your environment name for the pipeline is)\n",
    ">3. Terminal command: conda install jupyter\n",
    ">4. Terminal command: jupyter notebook\n",
    "\n",
    "**NOTE:** During your first run CRDS may download and cache reference files in $HOME/crds_cache.  On subsequent runs cached files will be used."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "from astropy.io import fits\n",
    "from urllib.request import urlretrieve\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "\n",
    "from jwst.pipeline import Detector1Pipeline\n",
    "from jwst.pipeline import Image2Pipeline\n",
    "from jwst.pipeline import Image3Pipeline\n",
    "from jwst import datamodels\n",
    "from jwst.pipeline.collect_pipeline_cfgs import collect_pipeline_cfgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Quick & Dirty Plots"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_image(obj, index=None):\n",
    "    if isinstance(obj, str):\n",
    "        data = fits.getdata(obj)\n",
    "    else:\n",
    "        data = obj.data\n",
    "    image = data[index] if index is not None else data\n",
    "    fig = plt.figure(figsize=(12,12))\n",
    "    ax = fig.add_subplot(1, 1, 1)\n",
    "    im = ax.imshow(image, origin='lower') # , norm=norm)\n",
    "    fig.colorbar(im)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"download_from_mast\"></a>\n",
    "## Download Data from MAST\n",
    "\n",
    "Test data can be downloaded from MAST using Astroquery"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAST_URI_PREFIX = \"https://pwjwdmsauiweb.stsci.edu/portal/Download/file?uri=mast:JWST/product/\" \n",
    "\n",
    "def download_mast(data_name,  local_name):\n",
    "    return urlretrieve(MAST_URI_PREFIX + data_name,  local_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "download_mast(\"jw00608002001_02101_00001_mirimage_uncal.fits\", \"test.fits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"pipeline_with_defaults\"></a>\n",
    "## Run Pipeline With Default Configuration\n",
    "\n",
    "Pipelines can be run by using the .call() method on the Pipeline class and passing in a data file.   Running a pipeline generally executes each successive step on the output from the previous step.  The end result is an output data model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model = Detector1Pipeline.call(\"test.fits\")\n",
    "output_model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id='pipeline_configs'></a>\n",
    "## About Configuration Files\n",
    "\n",
    "Configuration files are optional inputs for each step of the pipeline, as well as for the pipeline itself. These files list step-specific parameters, and can also be used to control which steps are run as part of the pipeline.\n",
    "\n",
    "You can get the full compliment of configuration files using the collect_pipeline_cfgs convenience function from the command line:\n",
    "\n",
    "    $ collect_pipeline_cfgs ./cfgs\n",
    "    \n",
    "This will store every .cfg file for all JWST instruments in a directory named \"cfgs\".   Note that default parameters in the config files are not necessarily optimized for any particular instrument.\n",
    "    \n",
    "A Python equivalent can also be imported and called from your notebook,  see below.\n",
    "\n",
    "Each of these configuration files can be customized to control pipeline behavior. For example, the configuration file for the Level 1 detector pipeline is called calwebb_detector1.cfg and contains a list (not necessarily in order) of the steps run as part of the Level 1 pipeline.\n",
    "\n",
    "```\n",
    "name = \"Detector1Pipeline\"\n",
    "class = \"jwst.pipeline.Detector1Pipeline\"\n",
    "save_calibrated_ramp = False\n",
    "\n",
    "    [steps]\n",
    "      [[group_scale]]\n",
    "        config_file = group_scale.cfg\n",
    "      [[dq_init]]\n",
    "        config_file = dq_init.cfg\n",
    "      [[saturation]]\n",
    "        config_file = saturation.cfg\n",
    "      [[ipc]]\n",
    "        skip = True\n",
    "      [[superbias]]\n",
    "        config_file = superbias.cfg\n",
    "      [[refpix]]\n",
    "        config_file = refpix.cfg\n",
    "      [[rscd]]\n",
    "        config_file = rscd.cfg\n",
    "      [[firstframe]]\n",
    "        config_file = firstframe.cfg\n",
    "      [[lastframe]]\n",
    "        config_file = lastframe.cfg\n",
    "      [[linearity]]\n",
    "        config_file = linearity.cfg\n",
    "      [[dark_current]]\n",
    "        config_file = dark_current.cfg\n",
    "      [[persistence]]\n",
    "        config_file = persistence.cfg\n",
    "      [[jump]]\n",
    "        config_file = jump.cfg\n",
    "      [[ramp_fit]]\n",
    "        config_file = ramp_fit.cfg\n",
    "      [[gain_scale]]\n",
    "        config_file = gain_scale.cfg\n",
    "```\n",
    "\n",
    "In this example, the ipc step will be skipped (skip = True).\n",
    "\n",
    "Note that calwebb_detector1.cfg lists a configuration file for each pipeline step. You can customize a particular pipeline step by editing the parameters in its configuration file. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Config File Setup\n",
    "\n",
    "To obtain all config files in a \"cfgs\" directory execute the following cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# ! rm -rf ./cfgs    # uncomment to delete your cfgs\n",
    "if not os.path.exists(\"./cfgs\"):\n",
    "    collect_pipeline_cfgs('./cfgs')\n",
    "! ls cfgs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"pipeline_with_cfgs\"></a>\n",
    "## Run Pipeline with Configuration Files\n",
    "\n",
    "In your cfgs directory, edit the file calwebb_detector1.cfg and change this:\n",
    "\n",
    "      [[dark_current]]\n",
    "        config_file = dark_current.cfg\n",
    "        \n",
    "to this:\n",
    "\n",
    "      [[dark_current]]\n",
    "        config_file = dark_current.cfg\n",
    "        save_results = True\n",
    "\n",
    "by executing the following cell (for demo purposes only) and printing the resulting calwebb_detector1_with_save.cfg file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is pretending to be you creating and editing a new .cfg file.   In real life,  you'd edit the file.\n",
    "\n",
    "! cp cfgs/calwebb_detector1.cfg  cfgs/calwebb_detector1_with_save.cfg\n",
    "! perl -pi -e's/      \\[\\[dark_current\\]\\]\\n/      \\[\\[dark_current\\]\\]\\n        save_results = True\\n/g' cfgs/calwebb_detector1_with_save.cfg\n",
    "! cat cfgs/calwebb_detector1_with_save.cfg\n",
    "\n",
    "# And the result is..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Normally just use menu File -> New -> Terminal and then edit with emacs or vi.  Alternatively use the programmatic methods demoed later."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output_model = Detector1Pipeline.call(\"test.fits\", config_file='cfgs/calwebb_detector1_with_save.cfg')\n",
    "output_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!ls test_dark_current.fits   # you should see a file since you set save_results=True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image(output_model.data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_image(\"test_dark_current.fits\", index=(0,0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"pipeline_no_configs\"></a>\n",
    "## Run Pipeline with Parameters Set Programmatically\n",
    "\n",
    "You can also run the pipeline without relying on configuration files by setting parameters programmatically, and relying on the defaults in the pipeline.   This is the pure-Python alternative to editing .cfg files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! rm -f test_dark_current.fits   # remove the dark current output,  we'll recreate it another way...\n",
    "\n",
    "det1p = Detector1Pipeline()\n",
    "det1p.dark_current.save_results = True\n",
    "det1p.run(\"test.fits\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting save_results=True results in the output of the test_dark_current.fits file which can be passed into the PersistenceStep when run in isolation, next."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls test_dark_current.fits   # make sure save_results worked."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"steps_with_config_files\"></a>\n",
    "## Run Individual Steps with Configuration Files\n",
    "\n",
    "You can also change parameter values in the .cfg files for individual Steps.\n",
    "\n",
    "Edit the cfgs/persistence.cfg file and change:\n",
    "\n",
    "```\n",
    "   input_trapsfilled = \"\"\n",
    "   flag_pers_cutoff = 40.\n",
    "   save_persistence = False\n",
    "```\n",
    "\n",
    "to:\n",
    "\n",
    "```\n",
    "   input_trapsfilled = \"\"\n",
    "   flag_pers_cutoff = 40.\n",
    "   save_persistence = True\n",
    "```\n",
    "\n",
    "This will cause PersistenceStep to output a third output file with suffix “_output_pers”. \n",
    "\n",
    "See https://jwst-pipeline.readthedocs.io/en/latest/jwst/persistence/description.html\n",
    "for more information on the persistence step."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# This cell is pretending to be you creating and editing a new .cfg file.    In real life, you'd edit the file.\n",
    "\n",
    "! cp cfgs/persistence.cfg  cfgs/persistence_with_out_pers_save.cfg\n",
    "! perl -pi -e's/save_persistence = False/save_persistence = True/g' cfgs/persistence_with_out_pers_save.cfg\n",
    "! cat cfgs/persistence_with_out_pers_save.cfg\n",
    "\n",
    "# And the result is..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from jwst.persistence.persistence_step import PersistenceStep\n",
    "\n",
    "output_model = PersistenceStep.call(\"test_dark_current.fits\", config_file=\"cfgs/persistence_with_out_pers_save.cfg\")\n",
    "\n",
    "output_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "! ls *.fits    # save_persistence may not be working..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "<a id=\"pipelines_level_123\"></a>\n",
    "## Run Level 1, 2, 3, Pipelines in Succession"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This section runs the test data through all stages of processing,  chaining the output of each processing level to the input of the next.   Output can optionally be saved to a file.   Alternatively,  in-memory pipeline output can\n",
    "be passed directly to the next level.\n",
    "\n",
    "Documentation on all JWST CAL pipelines can be found here: https://jwst-pipeline.readthedocs.io/en/latest/jwst/pipeline/main.html#pipelines"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Level 1\n",
    "\n",
    "Stage 1 consists of detector-level corrections that are performed on a group-by-group basis, followed by ramp fitting. The output of stage 1 processing is a countrate image per exposure, or per integration for some modes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output1 = Detector1Pipeline.call(\"test.fits\", config_file=\"cfgs/calwebb_detector1.cfg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Level 2\n",
    "\n",
    "Stage 2 processing consists of additional instrument-level and observing-mode corrections and calibrations to produce fully calibrated exposures. The details differ for imaging and spectroscopic exposures, and there are some corrections that are unique to certain instruments or modes. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output2 = Image2Pipeline.call(output1, config_file=\"cfgs/calwebb_image2.cfg\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run Level 3\n",
    "\n",
    "Stage 3 processing consists of routines that work with multiple exposures and in most cases produce some kind of combined product. There are unique pipeline modules for stage 3 processing of imaging, spectroscopic, coronagraphic, AMI, and TSO observations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "output3 = Image3Pipeline.call(output2[0], config_file=\"cfgs/calwebb_image3.cfg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
